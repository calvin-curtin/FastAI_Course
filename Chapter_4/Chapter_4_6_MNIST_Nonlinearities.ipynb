{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from previous excercises\n",
    "\n",
    "# Downloading a sample of MNIST containing just 3 and 7s supplied by fastai\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "\n",
    "# Creating the Training Set\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "dataset = list(zip(train_x, train_y))\n",
    "\n",
    "# Creating the Validation Set\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()]).float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]).float()/255\n",
    "\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dataset = list(zip(valid_x, valid_y))\n",
    "\n",
    "# Creating DataLoaders\n",
    "dl = DataLoader(dataset, batch_size=256)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=256)\n",
    "\n",
    "# Initialising Parameters\n",
    "def init_params(size, var=1.0): return (torch.randn(size)*var).requires_grad_()\n",
    "\n",
    "# Defining the Loss Function\n",
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()\n",
    "    \n",
    "# Calculating Gradients\n",
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()\n",
    "\n",
    "# Calculating Validation Accuracy\n",
    "def batch_accuracy(xb,yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(),4)\n",
    "\n",
    "# Creating DataLoaders object\n",
    "dls = DataLoaders(dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a Nonlinearity\n",
    "\n",
    "So far, we have a general procedure for optimising the parameters of a function, and we have tried it out on a very boring function: a simple linear classifier. A linear classifier is very constrained in what it can do. To make it a bit more complex (and able to handle more tasks), we need to add something non-linear between two linear classifiers - this is what gives us a neural network.\n",
    "\n",
    "Here is the entire definition of a basic neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_net(xb):\n",
    "    res = xb@w1 + b1\n",
    "    res = res.max(tensor(0.0))\n",
    "    res = res@w2 + b2\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! All we have in `simple_net` is two linear classifiers with a `max` function between them.\n",
    "\n",
    "Here, `w1` and `w2` are weight tensors, and `b1` and `b2` are bias tensors which are parameters that are initially randomised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = init_params((28*28, 30))\n",
    "b1 = init_params(30)\n",
    "\n",
    "w2 = init_params((30, 1))\n",
    "b2 = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key point about this is that `w1` has 30 output activations (which means that `w2` must have 30 input activations, so they match). That means that the first layer can construct 30 different features, each representing some different mix of pixels. You can change that `30` to anything you like, to make the model more or less complex.\n",
    "\n",
    "The little function `res.max(tensor(0.0))` is called a *rectified linear unit*, also known as *ReLU*. All it does is replace every negative number with a zero. This tiny function is also available in PyTorch as `F.relu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(F.relu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is that by using more linear layers, we can have our model do more computation, and therefore model more complex functions. But there's no point just putting one linear layer directly after another one, because when we multiply things together and add them up multiple times, that could be replaced by multiplying different things together and adding them up just once. That is to say, a series of any number of linear layers in a row can be replaced with a single linear layer with a different set of parameters.\n",
    "\n",
    "But if we put a non-linear function between them, such as `max`, then this is no longer true. Now each linear layer is actually somewhat decoupled from the other one, and can do its own useful work. The `max` function is particularly interesting, because it operates as a simple `if` statement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazingly enough, it can be mathematically prove that this little function can solve any computable problem to an arbitrarily high level of accuracy, if you can find the right parameters for `w1` and `w2` and if you make these matrices big enough. This is known as the *universal approximation theorem*. The three lines of code that we have above are known as *layers*. The first and third are known as *linear layers*, and the second line of code is known variously as *nonlinearity* or **activation function**.\n",
    "\n",
    "Taking advantage of PyTorch, we can replace the above code with something simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28, 30),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` creates a module that will call each of the listed layers or functions in turn.\n",
    "\n",
    "`nn.ReLU` is a PyTorch module that does the same thing as the `F.relu` function. Most functions that can appear in a model also have identical forms that are modules. When using `nn.Sequential`, PyTorch requires us to use the module version. Since modules are classes, we have to instantiate them, which is why you see `nn.ReLU()`.\n",
    "\n",
    "Because `nn.Sequential` is a module, we can get its parameters, which will return a list of all the parameters of the modules it contains.\n",
    "Let's try it out with a lower learning rate and a few more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=batch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>batch_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.288289</td>\n",
       "      <td>0.413854</td>\n",
       "      <td>0.504416</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.222317</td>\n",
       "      <td>0.812071</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.077730</td>\n",
       "      <td>0.113751</td>\n",
       "      <td>0.916585</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.052016</td>\n",
       "      <td>0.077751</td>\n",
       "      <td>0.940137</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.039915</td>\n",
       "      <td>0.061019</td>\n",
       "      <td>0.955348</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033623</td>\n",
       "      <td>0.051468</td>\n",
       "      <td>0.963199</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029940</td>\n",
       "      <td>0.045399</td>\n",
       "      <td>0.966634</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.041244</td>\n",
       "      <td>0.966143</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025752</td>\n",
       "      <td>0.038229</td>\n",
       "      <td>0.968106</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024382</td>\n",
       "      <td>0.035937</td>\n",
       "      <td>0.969578</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023270</td>\n",
       "      <td>0.034127</td>\n",
       "      <td>0.971050</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.022344</td>\n",
       "      <td>0.032647</td>\n",
       "      <td>0.972522</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.031406</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.020878</td>\n",
       "      <td>0.030344</td>\n",
       "      <td>0.974485</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.020284</td>\n",
       "      <td>0.029419</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.019759</td>\n",
       "      <td>0.028604</td>\n",
       "      <td>0.975466</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.027878</td>\n",
       "      <td>0.975957</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.018869</td>\n",
       "      <td>0.027229</td>\n",
       "      <td>0.976448</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.018486</td>\n",
       "      <td>0.026642</td>\n",
       "      <td>0.977429</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.018137</td>\n",
       "      <td>0.026110</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.017816</td>\n",
       "      <td>0.025627</td>\n",
       "      <td>0.978901</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.017519</td>\n",
       "      <td>0.025184</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.024777</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.016987</td>\n",
       "      <td>0.024402</td>\n",
       "      <td>0.979882</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.016746</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.016520</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.016306</td>\n",
       "      <td>0.023435</td>\n",
       "      <td>0.980373</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>0.980864</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.015913</td>\n",
       "      <td>0.022899</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.015731</td>\n",
       "      <td>0.022657</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.015392</td>\n",
       "      <td>0.022217</td>\n",
       "      <td>0.981354</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.015233</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>0.981845</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.015081</td>\n",
       "      <td>0.021827</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.014935</td>\n",
       "      <td>0.021649</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.014795</td>\n",
       "      <td>0.021480</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.014660</td>\n",
       "      <td>0.021321</td>\n",
       "      <td>0.982336</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.014529</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.021026</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.020890</td>\n",
       "      <td>0.982826</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(40, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the training process is recorded in `learn.recorder`, with the table of output stored in the `values` attribute, we can plot the accuracy over training as follows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x16a824e20>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD6CAYAAACxrrxPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYdUlEQVR4nO3de3Bc91nG8e+rXe3K1sWXWLHd2Imd1KnthiZthEu5htKLEwqhwHRiLg0dmBBIoMBAm7YzBabMQClluDTgMW0mTQvNP0moaU1Dp1wCNKWxEyexI7l1c7NiKbZjJ7uyd6W9vPyxZ+XVeiWt5ZV3zznPZ2ZHOhevXp2RH/30nsvP3B0REQm/rnYXICIiraFAFxGJCAW6iEhEKNBFRCJCgS4iEhEKdBGRiJg30M3sHjM7ZmYHZtluZvY3ZnbYzJ4ys7e0vkwREZlPsol97gU+A9w3y/YbgU3B663A3wcf57Rq1SrfsGFDU0WKiEjFvn37Trj7YKNt8wa6uz9iZhvm2OVm4D6v3KH0LTNbbmZr3X1srvfdsGEDe/fune/Li4hIDTN7YbZtreihXwYcqVkeDdaJiMhF1IpAtwbrGj5PwMxuM7O9Zrb3+PHjLfjSIiJS1YpAHwXW1yyvA4422tHdd7n7kLsPDQ42bAGJiMgCtSLQdwPvD652+QHgtfn65yIi0nrznhQ1sy8BNwCrzGwU+EOgG8DddwJ7gJuAw8AZ4AOLVayIiMyumatcdsyz3YE7WlaRiIgsiO4UFRGJiGZuLBKRGHF3JotlTk8WKZbnngAn0WWkkl2kEpVXV1eji96aUyo7hVKZyWKZqWKZQqnycaruY3X9PKVdkLL72a8ffM3JoIZC0SmVyxf0/kMbVvKjV7f+whAFush5cndKZZ8OmPlCr1z26TCYEVR1YXU2wHxGkFzIpGJl9yCEzg3GqWKZfBDcE/kiE5NFTk9VPp/ve5pNssvoTnSRSnbRnehirnwvO0wVSxRKlRpLi5nQi8AW/ruL23/sKgW6yHzKZedMoXQ2oILXq7kCJ09P8eqZKU6eLnDqzBQnT09x6kzlVSrNHiZlpxK2NYEYppkbuxNGKtFFdzCS7k50kU5WQjed7KKvJ8klvUvp60nSl07Sm6587Esn6U7M3pV1gl9sdb8kan8xzXJLSsBIJ7sq9SW7SCUSdCcrtaaDXwip5NlfDqlkF+ma7yNxAX8NNKNRDdV1i/21F0qBLk0plsqcKZRm3e4Ok8VKkJ6eLDExeTZQqx/nGoBV/8SdOXo9GxazjTCrQZubKlXCe2r2Gqv60klW9HazcmmKlb0prlzVO2dwATP+Q9cGTCrRRTJhDe+uqzKz6fCsBmp9SNS/Z2p6lGt0XcBQ0Kzy9SUeFOgxl5sqcfLMFKdOT3FiYpJjmUnGM3nGM3mOBR9fzkxyYmLyooxKa/9knw63GaO4SvD19yRnjKB6kgn6eqqjy8SMUWZvOsnypZUAX7a0m3QysfjfiEgbKNAjZLJY4tUzldbCqdNT00Fd32Ko3Z4vND65s7I3xaX9adYs6+GNa5exelkPAz1z/7ikuxP0BwHam07Qn+6mN52gL51kaTpJcp4/Uzv5T1mRMFCgd7By2Tl1ZioYJVdGyq9MTM4a0HO1GwZ6kqzorbQY1gz0sGXtACuWdlfWLU2xojfFJb0pVg/0cOlAWqNYkRBSoC+iUtl5/pXTjIxlGR7LMDKe4eir+bPtgwY91XyhxMuZScZfy3Msm6fQ4GRdbyoxHc4rlqa4arCPFUtTrFjazcq+swFd3b58afe8PWIRCT8Fegsdy+Z5+MA4B49mGB7P8p3xLLngRGKiy7hyVS/rVy6lWHYKxTL5QplMrjjjettUsos1Az1s27iS1QM9rB5Is2agh9XLelg90MMlvSl6ujV6FpFzKdAvkLvz7edO8oVvvcDXDoxTLDvLl3azZc0AO7Zdzua1/WxdO8DrL+1TEIvIolKgL9DEZJGHnniJLz76AodezjLQk+TWH9zAjm2Xc9Vgry4VE5GLToF+ng4fy3Lfoy/w4OMvMTFZ5I2vG+CTP/d9/PS1l7EkpRG4iLSPAr1J7s6uR57lk18bIdnVxXvetJZfetsVvHn9co3GRaQjKNCbkJsq8aEHnuJfnjzKTd+3hk/cfA2X9KXbXZaIyAwK9HkcOXmGX//CPobHM/zBu9/Ab95wlUbkItKRFOhz+Ob3TnDnPz1BoVTmnlu/nx/ffGm7SxIRmZUCvQF3595vPs+ffHWYjat62fXL13PlYF+7yxIRmZMCvU6+UOJjDx3ggcdHeefW1fzl+66lv6e73WWJiMxLgV4jXyjxi5/9P/a9cIrfeccmfvvtmy5oBhYRkYtJgR5wdz760NPse+EUf7vjzfzUta9rd0kiIudFT2wK3PvN53nw8Zf43XdcrTAXkVBSoAOPfu8V/uSrw7xr62p+6+2vb3c5IiILEvtAHz11hjv+6XE2rurl0++7Vj1zEQmtWAd6vlDi9i/uo1Aqs+uXr9fVLCISarE9KerufOTBpzl4NMPnbh3SdeYiEnqxHaF/7n+e46EnXuL33nE1b9+8ut3liIhcsFgG+jcPn+BP/3WE7W9cwx0/rpOgIhINsQv0IycrJ0GvXNXLX+gkqIhESOwC/RNfeYZi2dn1/iH60rE9hSAiERS7QN9/5FXetXUNG1f1trsUEZGWilWgvzIxybHsJFvW9re7FBGRlotVoB8azwKwec1AmysREWm9pgLdzLab2SEzO2xmdzXYvsLMHjKzp8zs22Z2TetLvXDPjGUA2KwRuohE0LyBbmYJ4G7gRmArsMPMttbt9lFgv7u/CXg/8NetLrQVRsazDPanWaX5QEUkgpoZoW8DDrv7s+4+BdwP3Fy3z1bgGwDuPgJsMLOOu1tnZDzD5jUanYtINDUT6JcBR2qWR4N1tZ4EfhbAzLYBVwDr6t/IzG4zs71mtvf48eMLq3iBiqUy33l5gi1r1T8XkWhqJtAb3Xnjdct/Bqwws/3AbwFPAMVz/pH7LncfcvehwcHB8631gjx34jRTxbJG6CISWc3cWTMKrK9ZXgccrd3B3TPABwDMzIDnglfHGA6ucNEIXUSiqpkR+mPAJjPbaGYp4BZgd+0OZrY82Abwa8AjQch3jJGxDMku4yo9VVFEImreEbq7F83sTuBhIAHc4+4Hzez2YPtOYAtwn5mVgGeAX13EmhdkZDzL6y/tI5WM1aX3IhIjTT3MxN33AHvq1u2s+fxRYFNrS2ut4bEMb924st1liIgsmlgMV189M8XYa3n1z0Uk0mIR6CPVW/4V6CISYbEI9OHglv8tumRRRCIsFoE+MpZlZW+KwX7d8i8i0RWPQB/PsGVtP5VL5EVEoinygV4qO4dezuqRuSISeZEP9OdfOU2+oFv+RST6Ih/oI2O65V9E4iH6gT6eIdFlvP5S3fIvItEW+UAfHsty5apeeroT7S5FRGRRxSDQM7qhSERiIdKBnskXeOnVHFs0h6iIxECkA/1Q9RnoumRRRGIg0oE+Etzyv1kjdBGJgUgH+jNjWZYt6WbNQE+7SxERWXSRDnTd8i8icRLZQC+XnUPjuuVfROIjsoH+4skznJkq6QoXEYmNyAb6yHhwQlQjdBGJicgG+vBYli6Dq1drhC4i8RDZQB8Zz7BhVS9LUrrlX0TiIbKBPjyW1Q1FIhIrkQz0ickiL548o2egi0isRDLQp2/510O5RCRGIhno01e46JJFEYmRSAb68FiG/nSSy5YvaXcpIiIXTSQDfWQsy2bd8i8iMRO5QHd3Rsaz6p+LSOxELtBHT+WYmCzqDlERiZ3IBfqwnoEuIjEVuUCvXrL4Bt3yLyIxE7lAPzExybIl3fSmk+0uRUTkomoq0M1su5kdMrPDZnZXg+3LzOxfzOxJMztoZh9ofanNyeSLDCxRmItI/Mwb6GaWAO4GbgS2AjvMbGvdbncAz7j7tcANwKfNLNXiWpuSyRXoT3e340uLiLRVMyP0bcBhd3/W3aeA+4Gb6/ZxoN8qF373ASeBYksrbVImX9AIXURiqZlAvww4UrM8Gqyr9RlgC3AUeBr4oLuXW1Lhecrmiwz0aIQuIvHTTKA3ut3S65bfDewHXgdcB3zGzM65ENzMbjOzvWa29/jx4+dZanMyuQIDSxToIhI/zQT6KLC+ZnkdlZF4rQ8AD3rFYeA5YHP9G7n7LncfcvehwcHBhdY8p0y+SH+PWi4iEj/NBPpjwCYz2xic6LwF2F23z4vATwCY2WrgDcCzrSy0GaWyMzGplouIxNO8Q1l3L5rZncDDQAK4x90PmtntwfadwCeAe83saSotmg+7+4lFrLuhiXzlPKxaLiISR031Jtx9D7Cnbt3Oms+PAu9qbWnnL5MvAKjlIiKxFKk7RV/LVQJdLRcRiaNIBXp2uuWiEbqIxE+kAr3actEIXUTiKFqBrpaLiMRYpAJdLRcRibNIBXq15dKnR+eKSAxFK9BzRXpTCZKJSH1bIiJNiVTyVZ60qP65iMRTpAI9my/ohKiIxFakAj2T02xFIhJf0Qr0fIF+jdBFJKYiFeiVyS00QheReIpUoOukqIjEWWQC3d0rE0RrhC4iMRWZQD89VaLsuu1fROIrMoGerT6YSy0XEYmpyAR6Jhc8x0UjdBGJqegEumYrEpGYi0ygq+UiInEXmUA/23LRCF1E4ik6ga4RuojEXGQCvTq5hXroIhJXkQn0TK5AOtlFOplodykiIm0RnUDXbf8iEnPRCfRcUe0WEYm16AS6JrcQkZiLUKAX1XIRkViLTKBncwVdgy4isRaZQM/ki5qtSERiLUKBXtB8oiISa5EI9HyhxFSxrJOiIhJrkQj06dv+1UMXkRhrKtDNbLuZHTKzw2Z2V4Ptf2Bm+4PXATMrmdnK1pfbWPW2f13lIiJxNm+gm1kCuBu4EdgK7DCzrbX7uPun3P06d78O+AjwX+5+chHqbSiTq47QFegiEl/NjNC3AYfd/Vl3nwLuB26eY/8dwJdaUVyzMtMjdLVcRCS+mgn0y4AjNcujwbpzmNlSYDvwwIWX1rzs9GxFGqGLSHw1E+jWYJ3Psu9PAf87W7vFzG4zs71mtvf48ePN1jgvzScqItJcoI8C62uW1wFHZ9n3FuZot7j7LncfcvehwcHB5qucx9nJLdRyEZH4aibQHwM2mdlGM0tRCe3d9TuZ2TLgx4Avt7bE+WVyBRJdxpJuPQtdROJr3iGtuxfN7E7gYSAB3OPuB83s9mD7zmDX9wL/5u6nF63aWWTzRQZ6kpg16g6JiMRDUz0Kd98D7Klbt7Nu+V7g3lYVdj40uYWISFTuFM3pWegiIpEI9GxesxWJiEQi0DVbkYhIVAI9V9QliyISe9EI9HxBd4mKSOyFPtCLpTJnpkpquYhI7IU+0LN6MJeICBCBQD87uYVG6CISb6EP9OoIXZctikjchT7Qpye30J2iIhJz4Q90tVxERIAoBHpOLRcREYhCoOfVchERgUgEehEz6E9rhC4i8Rb+QM8V6Esn6erSs9BFJN5CH+iVyS3UbhERCX2gV57jonaLiEj4Az2n2YpERCAKgR7MJyoiEnehD/SsJrcQEQEiEOhquYiIVIQ60MtlJzuplouICIQ80E9PFXFHsxWJiBDyQM9ocgsRkWnhDvScnrQoIlIViUBXy0VEJOSBrvlERUTOCnWga3ILEZGzwh3omn5ORGRaqANdE0SLiJwV6kDP5Ass6U7QnQj1tyEi0hKhTsJMrqgToiIigaYC3cy2m9khMztsZnfNss8NZrbfzA6a2X+1tszGspMFXbIoIhKYd3hrZgngbuCdwCjwmJntdvdnavZZDvwdsN3dXzSzSxep3hkyOT3HRUSkqpkR+jbgsLs/6+5TwP3AzXX7/ALwoLu/CODux1pbZmOZvJ60KCJS1UygXwYcqVkeDdbVuhpYYWb/aWb7zOz9rSpwLpmcnoUuIlLVTL/CGqzzBu9zPfATwBLgUTP7lrt/Z8Ybmd0G3AZw+eWXn3+1dbL5oi5ZFBEJNDNCHwXW1yyvA4422Odr7n7a3U8AjwDX1r+Ru+9y9yF3HxocHFxozdX3UstFRKRGM4H+GLDJzDaaWQq4Bdhdt8+XgR8xs6SZLQXeCgy3ttSZ8oUyhZKr5SIiEpi3X+HuRTO7E3gYSAD3uPtBM7s92L7T3YfN7GvAU0AZ+Ky7H1jMwrPV57joOnQREaC5HjruvgfYU7duZ93yp4BPta60uVUfzKXr0EVEKkJ7p+hrueDRuTopKiIChDjQpx+dq5OiIiJAiAN9enILjdBFRIAQB7rmExURmSm8ga6Wi4jIDKEN9Gy+SCrRRToZ2m9BRKSlQpuGmVyB/p4kZo2eTCAiEj/hDfR8Ue0WEZEa4Q30XEFXuIiI1AhtoGfzmq1IRKRWaAO90nLRCF1EpCq8ga7JLUREZghtoGd1UlREZIZQBvpUsUyuUKI/rZaLiEhVKAM9q7tERUTOEcpAz1QfzKWToiIi00IZ6NURen9aI3QRkapQBnqmOrmFWi4iItPCGeiaT1RE5ByhDPTpk6K6Dl1EZFooA73acunXs1xERKaFM9DzBboMelMKdBGRqnAGeq7yYK6uLj0LXUSkKpSBns0X1W4REakTykDP5PVgLhGReuEM9JwenSsiUi+cga4RuojIOUIZ6JUeugJdRKRWKAM9kyuo5SIiUid0gV4qO9nJolouIiJ1QhfoE5O6S1REpJHQBXomp8ktREQaCV+g68FcIiINNRXoZrbdzA6Z2WEzu6vB9hvM7DUz2x+8Pt76Uiuymq1IRKSheVPRzBLA3cA7gVHgMTPb7e7P1O363+7+nkWocYbplotG6CIiMzQzQt8GHHb3Z919CrgfuHlxy5rdJX0pbrxmDYP96XaVICLSkZrpW1wGHKlZHgXe2mC/t5nZk8BR4Pfd/WAL6jvH9Ves5PorVi7GW4uIhFozgd7oGbVet/w4cIW7T5jZTcA/A5vOeSOz24DbAC6//PLzq1RERObUTMtlFFhfs7yOyih8mrtn3H0i+HwP0G1mq+rfyN13ufuQuw8NDg5eQNkiIlKvmUB/DNhkZhvNLAXcAuyu3cHM1piZBZ9vC973lVYXKyIis5u35eLuRTO7E3gYSAD3uPtBM7s92L4T+HngN8ysCOSAW9y9vi0jIiKLyNqVu0NDQ7537962fG0RkbAys33uPtRoW+juFBURkcYU6CIiEaFAFxGJiLb10M3sOPDCAv/5KuBEC8tpJdW2MJ1cG3R2faptYcJa2xXu3vC677YF+oUws72znRRoN9W2MJ1cG3R2faptYaJYm1ouIiIRoUAXEYmIsAb6rnYXMAfVtjCdXBt0dn2qbWEiV1soe+giInKusI7QRUSkTugCfb7p8NrJzJ43s6eDafja+lwDM7vHzI6Z2YGadSvN7Otm9t3g44oOqu2PzOylmmkMb2pTbevN7D/MbNjMDprZB4P1bT92c9TW9mNnZj1m9m0zezKo7Y+D9Z1w3Garre3HrabGhJk9YWZfCZYXdNxC1XIJpsP7DjXT4QE7GkyH1xZm9jww5O5tv7bVzH4UmADuc/drgnV/Dpx09z8LfhmucPcPd0htfwRMuPtfXOx66mpbC6x198fNrB/YB/wM8Cu0+djNUdv7aPOxC5622hvMidAN/A/wQeBnaf9xm6227XTAzxyAmf0eMAQMuPt7Fvp/NWwj9I6aDq+TufsjwMm61TcDnw8+/zyVMLjoZqmtI7j7mLs/HnyeBYapzNrV9mM3R21t5xUTwWJ38HI647jNVltHMLN1wE8Cn61ZvaDjFrZAbzQdXkf8QAcc+Dcz2xfMztRpVrv7GFTCAbi0zfXUu9PMngpaMm1pB9Uysw3Am4H/o8OOXV1t0AHHLmgb7AeOAV939445brPUBh1w3IC/Aj4ElGvWLei4hS3Qm5kOr51+yN3fAtwI3BG0FqQ5fw9cBVwHjAGfbmcxZtYHPAD8jrtn2llLvQa1dcSxc/eSu19HZVazbWZ2TTvqaGSW2tp+3MzsPcAxd9/XivcLW6DPOx1eO7n70eDjMeAhKi2iTvJy0Iet9mOPtbmeae7+cvCfrgz8A208dkGf9QHgH939wWB1Rxy7RrV10rEL6nkV+E8qPeqOOG5VtbV1yHH7IeCng/Nv9wNvN7MvssDjFrZAn3c6vHYxs97gRBVm1gu8Czgw97+66HYDtwaf3wp8uY21zFD94Q28lzYdu+AE2ueAYXf/y5pNbT92s9XWCcfOzAbNbHnw+RLgHcAInXHcGtbWCcfN3T/i7uvcfQOVPPt3d/8lFnrc3D1UL+AmKle6fA/4WLvrqanrSuDJ4HWw3bUBX6LyZ2SByl82vwpcAnwD+G7wcWUH1fYF4GngqeCHeW2bavthKm28p4D9weumTjh2c9TW9mMHvAl4IqjhAPDxYH0nHLfZamv7caur8wbgKxdy3EJ12aKIiMwubC0XERGZhQJdRCQiFOgiIhGhQBcRiQgFuohIRCjQRUQiQoEuIhIRCnQRkYj4f8E3C2Q5xN0RAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(L(learn.recorder.values).itemgot(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can view the final accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.982826292514801"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.recorder.values[-1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have something that is amazing.\n",
    "1. A function that can solve any problem to any level of accuracy (the neural network) given the correct set of parameters\n",
    "2. A way to find the best set of parameters for any function (stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going Deeper\n",
    "\n",
    "There is no need to stop at just two linear layers. We can add as many as we want, as long as we add a non-linearity between each pair of linear layers. However, the deeper the model gets, the harder it is to optimise the parameters in practice.\n",
    "\n",
    "With a deeper model, we do not need to use as many parameters. It turns out that we can use smaller matrices with more layers, and get better results than we would get with larger matrices, and fewer layers. That means we can train the model more quickly, and it will take up less memory.\n",
    "\n",
    "Here is what happens when we train an 18-layer model using the same approach we saw previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.085801</td>\n",
       "      <td>0.008483</td>\n",
       "      <td>0.997547</td>\n",
       "      <td>03:27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = ImageDataLoaders.from_folder(path)\n",
    "learn = vision_learner(dls, resnet18, pretrained=False,\n",
    "                          loss_func=F.cross_entropy, metrics=accuracy)\n",
    "\n",
    "learn.fit_one_cycle(1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e90582675576e512e92beafc5221de7144a1dea5f49197901594ad708e1d2ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
