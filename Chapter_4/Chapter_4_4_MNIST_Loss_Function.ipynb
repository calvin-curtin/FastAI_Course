{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading a sample of MNIST containing just 3 and 7s supplied by fastai\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "\n",
    "# Creating the Training Set\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "\n",
    "three_tensors = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensors = [tensor(Image.open(o)) for o in sevens]\n",
    "\n",
    "stacked_threes = torch.stack(three_tensors).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensors).float()/255\n",
    "\n",
    "# Creating the Validation Set\n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()]).float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]).float()/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Loss Function\n",
    "\n",
    "All of what we saw in the Stochastic Gradient Descent excercise can be transposed directly to the MNIST dataset, except for the loss function.\n",
    "Here, we will see how we can define a good training objective.\n",
    "\n",
    "## Preparing our Training and Validation Sets\n",
    "We already have our independent variables *x* (the images themselves). So we'll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor). We can do this using ```view```, which is a PyTorch method that changes the shape of a tensor without changing its contents. ```-1``` is a special parameter to ```view``` that means \"make this axis as big as necessary to fit all the data\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Squishing our training data into a single tensor\n",
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need a label for each image, so let's use `1` for 3s and `0` for 7s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating labels for each image\n",
    "train_y = tensor([1]*len(threes) + [0]*len(sevens)).unsqueeze(1)\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ```Dataset``` in PyTorch is required to return a tuple of `(x,y)` when indexed. Python provides a `zip` function which, when combined with `list`, provides a simple way to get this functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = list(zip(train_x, train_y))\n",
    "\n",
    "# Grabbing an image from the dataset and displaying its shape\n",
    "x,y = dataset[0]\n",
    "x.shape, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to perform the same steps for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dataset = list(zip(valid_x, valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Initialise the Parameters\n",
    "We need an (initially random) weight for every pixel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(size, var=1.0): return (torch.randn(size)*var).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising random weights\n",
    "weights = init_params((28*28,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `weights*pixels` won't be flexible enough - it is always equal to 0 when the pixels are equal to 0.\n",
    "Remembering from linear algebra that the formula for a line is `y=w*x + b`, we still need the `b`.\n",
    "\n",
    "We'll initialise it to a random number too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising random bias\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In neural networks, the `w` in the equation `y=w*x+b` is called the *weights* and the `b` is called the *bias*. Together, the weights and bias make up the *parameters*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Calculate Predictions\n",
    "Let's first calculate a prediction for one image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-6.2330], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a single prediction\n",
    "(train_x[0]*weights.T).sum() + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could use a Python `for` loop to calculate the prediction for each image, that would be very slow.\n",
    "\n",
    "In this case, we can use *matrix multiplication* which calculates `w*x` for every row of a matrix.\n",
    "\n",
    "In Python, matrix multiplication is represented with the `@` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate predictions using matrix multiplication\n",
    "def linear1(xb): return xb @ weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.2330],\n",
       "        [-10.6388],\n",
       "        [-20.8865],\n",
       "        ...,\n",
       "        [-15.9176],\n",
       "        [ -1.6866],\n",
       "        [-11.3568]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating predictions for all images in the dataset\n",
    "preds = linear1(train_x)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first element is the same as what we calculated before, as expected.\n",
    "\n",
    "This equation `batch@weights + bias` is one of the two fundamental equations of any neural network (the other one is the *activation function*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate the Loss\n",
    "To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0.0, so our accuracy for each item can be calculated (using broadcasting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False],\n",
       "        [False],\n",
       "        [False],\n",
       "        ...,\n",
       "        [ True],\n",
       "        [ True],\n",
       "        [ True]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating Accuracy\n",
    "corrects = (preds>0.0).float() == train_y\n",
    "corrects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5379961133003235"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Accuracy\n",
    "corrects.float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what the change in accuracy is for a small change in one of the weights.\n",
    "\n",
    "NOTE: We have to ask PyTorch not to calculate gradients as we do this, which is what `with torch.no_grad()` is doing here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5379961133003235"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad(): weights[0] *= 1.0001\n",
    "preds = linear1(train_x)\n",
    "((preds>0.0).float() == train_y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've seen before, we need gradients in order to improve our model using SGD, and in order to calculate gradients we need some *loss* function that represents how good our model is. That is because the gradients are a measure of how that loss function changes with small tweaks to the weights.\n",
    "\n",
    "So how do we choose a loss function? The obvious approach would be to use accuracy, which is our metric, as our loss function as well. In this case, we would calculate our prediction for each image, collect these values to calculate an overall accuracy, and then calculate the gradients of each weight with respect to that overall accuracy.\n",
    "\n",
    "Unfortunately, we have a significant technical problem here. The gradient of a function is its slope and is mathematically represented by `(y_new - y_old) / (x_new - x_old)`. As accuracy only changes at when a prediction changes from a 3 to a 7 or vice versa, a small change in weights from `x_old` to `x_new` isn't likely to cause any prediction change, so `(y_new - y_old)` will always be 0.\n",
    "In other words, the gradient is 0 almost everywhere. This means it is not useful to use accuracy as a loss function - if we do, most of the time our gradients will actually be 0 and the model will not be able to learn from that number.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need a loss function which, when our weights result in slightly better predictions, gives us a slightly better loss. Let's write such a function. What form does it take?\n",
    "\n",
    "The loss function receives not the images themselves, but the predictions from the model. Let's make one argument, `prds`, of values between 0 and 1, where each value is the prediction that an image is a 3. It is a vector (i.e., a rank-1 tensor), indexed over the images.\n",
    "\n",
    "The purpose of the loss function is the measure the difference between the predicted values and the true values - that is, the targets (aka labels). Let's make another argument, `trgts`, with values of 0 or 1 which tells wehther an image actually is a 3 or not. It is also a vector (i.e., another rank-1 tensor), indexed over the images.\n",
    "\n",
    "So, for instance, supposed we had three images which we knew were a 3, a 7, and a 3. And suppose our model predicted with high confidence `(0.9)` that the first was a 3, with a slight confidence `(0.4)` that the second was a 7, and with fair confidence `(0.2)`, but incorrectly, that the last was a 7. This would mean our loss function would received the following values as its inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgts = tensor([1,0,1])\n",
    "prds = tensor([0.9, 0.4, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a first try at a loss function that measures the distance between `predictions` and `targets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will measure how distant each prediction is from 1 if it should be 1, and how distant it is from 0 if it should be 0, and then it will take the mean of all those distances.\n",
    "\n",
    "Let's try it on our `prds` and `trgts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.4000, 0.8000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(trgts==1, 1-prds, prds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the function returns a lower number when predictions are more accurate. In PyTorch, we always assume that a lower value of loss function is better. \n",
    "\n",
    "Since we need a scalar for the final loss, `mnist_loss` takes the mean of the previous tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4333)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_loss(prds, trgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with `mnist_loss` as currently defined is that it assumes that predictions are always between 0 and 1. We need to ensure, then, that this is always the case.\n",
    "\n",
    "Fortunately, we can achieved this using the `sigmoid` function, which always outputs a number between 0 and 1. It is defined as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x): return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch defines an accelerated version of this for us though, so we don't really need our own. This is what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_function(torch.sigmoid, title=\"Sigmoid\", min=-4, max=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it takes any input value, positive or negative, and smooshes it onto an output value between 0 and 1. It's also a smooth curve that only goes up, which makes it easier for SGD to find meaningful gradients.\n",
    "\n",
    "Let's update `mnist_loss` to first apply `sigmoid` to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(predictions, targets):\n",
    "    predictions = predictions.sigmoid()\n",
    "    return torch.where(targets==1, 1-predictions, predictions).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can be confident that our loss function will work, even if the predictions are not between 0 and 1. All that is required is that a higher prediction corrections to a higher confidence an image is a 3.\n",
    "\n",
    "Having defined a loss function, let's recapitulate why we did this if we already had a metric.\n",
    "The key difference is that the metric is to drive human understanding and the loss is to drive automated learning. To drive automated learning, the loss must be a function that has a meaningful derivative. It can't have big flat sections and large jumps, but instead must be reasonably smooth. That is why we designed a loss function that would respond to small changes in confidence level. The loss function is calculated for each item in our dataset, and then at the end of an epoch the loss values are all averaged and the overall mean is reported for the epoch.\n",
    "\n",
    "Metrics on the other hand, are the numbers we really care about. These are the values that are printed at the end of each epoch that tell us how our model is really doing. It is important that we learn to focus on these metrics, rather than the loss, when judging the performance of a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Calculate the Gradients\n",
    "\n",
    "Now that we have our loss function that is suitable for driving SGD, we can consider some of the details involved in the next phase of the learning process, which is to change or update the weights based on gradients. Also called the *optimisation* step.\n",
    "\n",
    "In order to take an optimisation step, we need to calculate the loss over one or more data items. We could calculated it for the whole dataset, and take the average, or we could calculate it for a single item. Calculating it for the whole dataset would take a very long time. Calculating it for a single item would not use much information, so it would result in a very imprecise and unstable gradient. That is, we'd be going through the trouble of updating the weights, but taking into account only how that would improve the model's performance on that single item.\n",
    "\n",
    "Instead, we calculate the average loss for a few data items at a time, also known as a *mini-batch*. The number of data items in the mini-batch is called the *batch size*. A larger batch size means that you will get a more accurate and stable estimate of your dataset's gradients from the loss function, but it will take longer, and you will process fewer mini-batches per epoch. Choosing a good batch size is one of the decisions that you need to make to train your model more quickly and accurately.\n",
    "\n",
    "Another good reason for using mini-batches is that, in practice, we nearly always do our training on an GPU. These only perform well if you have lots of work to do at a time, so it's helpful if we can give them lots of data items to work on. Using mini-batches is one of the best ways to do this, however too many data items can result in them running out of memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalling our discussion on data augmentation, we can get better generalisation if we can vary things during training. One simple and effective thing we can vary is what data items we put in each mini-batch. Rather than simply enumerating our dataset in order for every epoch, instead what we normally do is randomly shuffle it on every epoch, before we create mini-batches. PyTorch and fastai provide a class that will do the shuffling and mini-batch collation for you, called `DataLoader`.\n",
    "\n",
    "A `DataLoader` can take any Python collection and turn it into an iterator over mini-batches, like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 3, 12,  8, 10,  2]),\n",
       " tensor([ 9,  4,  7, 14,  5]),\n",
       " tensor([ 1, 13,  0,  6, 11])]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating mini-batches using DataLoader\n",
    "col1 = range(15)\n",
    "dl = DataLoader(col1, batch_size=5, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training a model, we don't just want any Python collection, but a collection containing independent and dependent variables. A collection that contains tuples of independent and dependent variables is known in PyTorch as a `Dataset`.\n",
    "\n",
    "Here is an example of an extremely simple `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = L(enumerate(string.ascii_lowercase))\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we pass a `Dataset` to a `DataLoader`, we will get back mini-batches which are themselves tuples of tensors representing batches of independent and dependent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([17, 18, 10, 22,  8, 14]), ('r', 's', 'k', 'w', 'i', 'o')),\n",
       " (tensor([20, 15,  9, 13, 21, 12]), ('u', 'p', 'j', 'n', 'v', 'm')),\n",
       " (tensor([ 7, 25,  6,  5, 11, 23]), ('h', 'z', 'g', 'f', 'l', 'x')),\n",
       " (tensor([ 1,  3,  0, 24, 19, 16]), ('b', 'd', 'a', 'y', 't', 'q')),\n",
       " (tensor([2, 4]), ('c', 'e'))]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(ds, batch_size=6, shuffle=True)\n",
    "list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to write our first training loop for a model using SGD!.\n",
    "Our process will be implemented something like this for each epoch.\n",
    "```\n",
    "for x,y in dl:\n",
    "    pred = model(x)\n",
    "    loss = loss_func(pred,y)\n",
    "    loss.backward()\n",
    "    parameters -= parameters.grad * lr\n",
    "    parameters.grad = None\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's re-initialise our parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = init_params((28*28, 1))\n",
    "bias = init_params(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataLoader` can be created from a `Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(dataset, batch_size=256)\n",
    "\n",
    "xb,yb = first(dl)       # Grabs the first batch of data\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do the same for the Validation Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dl = DataLoader(valid_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a mini-batch of size 4 for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 784])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = train_x[:4]\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11.6180],\n",
       "        [ 9.0489],\n",
       "        [-2.4524],\n",
       "        [-2.5197]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = linear1(batch)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4616, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = mnist_loss(preds, train_y[:4])\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0057), tensor([-0.0355]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.backward()\n",
    "weights.grad.shape, weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all in a function and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = mnist_loss(preds, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0113), tensor([-0.0710]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.shape, weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what happens it we call it twice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), tensor(-0.0170), tensor([-0.1065]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_grad(batch, train_y[:4], linear1)\n",
    "weights.grad.shape, weights.grad.mean(), bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients have changed! The reason for this is that `loss.backward` actually *adds* the gradients of `loss` to any gradients that are currently stored. So we have to set the gradients back to zero first. This can be done using `.grad.zero_()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.grad.zero_()\n",
    "bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Step the Weights\n",
    "\n",
    "Our only remaining step is to update the weights and biases based on the gradient and learning rate. When we do so, we have to tell PyTorch not to take the gradient of this step too - otherwise things will get very confusing when we try to compute the derivative at the next batch!. If we assign the `data` attribute of a tensor, then PyTorch will not take the gradient of that step. Our basic training loop for each epoch now becomes the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, lr, params):\n",
    "    for xb,yb in dl:\n",
    "        calc_grad(xb, yb, model)\n",
    "        for p in params:\n",
    "            p.data -= p.grad*lr\n",
    "            p.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to check how we're doing, by looking at the accuracy of the validation set. To decide if an output represents a 3 or a 7, we can just check whether it's greater than 0. So our accuracy for each item can be calculated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True],\n",
       "        [ True],\n",
       "        [False],\n",
       "        [False]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds>0.0).float() == train_y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us this function to calculate our validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_accuracy(xb,yb):\n",
    "    preds = xb.sigmoid()\n",
    "    correct = (preds>0.5) == yb\n",
    "    return correct.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_accuracy(linear1(batch), train_y[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put the batches together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "    return round(torch.stack(accs).mean().item(),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5484"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's our starting point. Let's train for one epoch, and see if the accuracy improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6293"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training for 1 Epoch\n",
    "lr = 1.\n",
    "params = weights, bias\n",
    "train_epoch(linear1, lr, params)\n",
    "validate_epoch(linear1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Repeating the Process\n",
    "\n",
    "Let's repeat the above proess for 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8129 0.913 0.9442 0.956 0.9623 0.9667 0.9692 0.9706 0.9721 0.974 0.9745 0.975 0.976 0.9765 0.9765 0.977 0.9775 0.9775 0.9775 0.9775 "
     ]
    }
   ],
   "source": [
    "# Training for 20 Epochs\n",
    "for i in range(20):\n",
    "    train_epoch(linear1, lr, params)\n",
    "    print(validate_epoch(linear1), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a few epochs, we have reached the same accuracy as the \"Pixel Similarity\" approach, and we've created a general-purpose foundation we can build on.\n",
    "Our next step will be to create an object that will handle the SGD step for us. In PyTorch, it's called an optimizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e90582675576e512e92beafc5221de7144a1dea5f49197901594ad708e1d2ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
