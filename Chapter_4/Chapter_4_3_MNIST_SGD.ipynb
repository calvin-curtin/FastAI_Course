{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent (SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our Pixel Similarity approach, we do not have any kind of weight assignment, or any way of improving based on testing the effectiveness based on a weight assignment. In otherwords, we can't really improve our Pixel Similiarity approach by modifying a set of parameters. In order to take advantage of deep learning, we first need to represent our task in the way that Arthur Samuel described it.\n",
    "\n",
    "Instead of trying to find the similarity between an image and an \"ideal image\", we could instead look at each individual pixel and come up with a set of weights for each one, such that the highest weights are associated with those pixels most likely to be black for a particular category.\n",
    "For instance, pixels towards the bottom right are not very likely to be activated for a 7, so they should have a low weight for a 7, but they are likely to be activated for an 8, so they should have a high weight for an 8.\n",
    "\n",
    "This can be represented as a function and a set of weight values for each possible category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of being the number 8\n",
    "def pr_eight(x,w): return (x*w).sum()\n",
    "\n",
    "# x is the image, represented as a vector\n",
    "# w is the vector of weights\n",
    "\n",
    "# If we have the above function, then we just need some way to update the weights to make them a little bit better.\n",
    "# With such an approach, we can repeat that step a number of times, making the weights better and better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the specific values for the vector *w* that causes the result of our function to be high for those images that are actually 8s, and low for those images that are not. \n",
    "Searching for the best vector *w* is a way to search for the best function for recognising 8s.\n",
    "\n",
    "To be more specific, here are the steps that we are going to require, to turn this function into a machine learning classifier:\n",
    "1. Initialise the weights.\n",
    "2. For each image, use these weights to predict whether it appears to be a 3 or a 7.\n",
    "3. Based on these predictions, calculate how good the model is (its loss).\n",
    "4. Calculate the gradient, which measures for each weight, how changing that weight would change the loss.\n",
    "5. Step (that is, change) all the weights based on that calculation.\n",
    "6. Go back to step 2 and repeat the process.\n",
    "7. Iterate until you decide to stop the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Gradients\n",
    "\n",
    "The derivative of a function tells us how much a change in its parameters will change its result.\n",
    "If we know how our function wil lchange, then we know what we need to do to make it smaller.\n",
    "\n",
    "This is the key to machine learning: having a way to change the parameters of a function to make it smaller.\n",
    "Calculus provides us with a computational shortcut, the derivative, which lets us directly calculate the gradients of our functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important thing to remember is that our function has lots of weights that we need to adjust, so when we calculate the derivative we won't get back one number, but lots of them - a gradient for every weight.\n",
    "However, we can calculate the derivative with respect to one weight, and treat all the others as constant, then repeat that for each other weight.\n",
    "This is how all of the gradients are calculated for every weight.\n",
    "\n",
    "Fortunately, PyTorch is able to automatically compute the derivative of nearly any function very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple loss function\n",
    "def f(x): return x**2\n",
    "\n",
    "# A tensor value which we want gradients at\n",
    "xt = tensor(3.).requires_grad_()\n",
    "\n",
    "# requires_grad_() is a special method we use to tell PyTorch that we want to calculate gradients with respect to that variable at that value.\n",
    "# It tells PyTorch to remember to keep track of how to compute gradients of the other, direct calculations on it that you will ask for.\n",
    "\n",
    "# Calculating a function with that value.\n",
    "yt = f(xt)\n",
    "yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Telling PyTorch to calculate the gradients for us\n",
    "yt.backward()\n",
    "\n",
    "# The \"backward\" here referes to backpropagation, which is the name given to the process of calculating the derivative of each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viewing the gradients attribute of our tensor\n",
    "xt.grad\n",
    "\n",
    "# The derivative of x**2 is 2*x\n",
    "# Since we have x=3, the gradient should be 2*3=6 which is what PyTorch calculated for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating the above steps but with a vector argument for our function\n",
    "\n",
    "def f(x): return (x**2).sum()       # Adding .sum() so it can take a rank-1 tensor and return a scalar\n",
    "\n",
    "xt = tensor([3., 4., 10.]).requires_grad_()\n",
    "\n",
    "yt = f(xt)\n",
    "\n",
    "yt.backward()\n",
    "xt.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradients only tell us the slope of our function, they don't actually tell us exactly how far to adjust the parameters. But it gives us some idea of how far; if the slope is very large, then that may suggest that we have more adjustments to do, whereas if the slope is very small, that may suggest that we are close to the optimal value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepping with Learning Rate\n",
    "\n",
    "Deciding how to change our parameters based on the values of the gradients is an important part of the deep learning process.\n",
    "Nearly all approaches start with the basic idea of multiplying the gradient by some small number, called the *learning rate* (LR).\n",
    "\n",
    "The learning rate is often a number between 0.001 and 0.1, although it could be anything. Once you've picked a learning rate, you can adjust your parameters using the following simple function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser Step\n",
    "w -= gradient(w) * lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is known as *stepping* your parameters, using an *optimizer* step. \n",
    "\n",
    "Notice how we subtract the ```gradient * lr``` from the parameter to update it. This allows us to adjust the parameter in the direction of the slope by increasing the parameter when the slope is negative and decreasing the parameter when the slope is positive.\n",
    "\n",
    "We want to adjust the parameters in the direction of the slope because our goal in deep learning is to *minimise* the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End SGD Example\n",
    "\n",
    "Let's look at an SGD example and see how finding a minimum can be used to train a model to fit data better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with a simple, synthetic, example model. Imagine if you were measuring the speed of a roller coaster as it went over the top of a hump. It would start fast, and then get slower as it went up the hill; it would be slowest at the top, and it would then speed up again as it went downhill. You want to build a model of how the speed changes over time. If you were measuring the speed manually every second for 20 seconds, it might look something like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time between 0 and 20s\n",
    "time = torch.arange(0,20).float(); time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Speed of rollercoaster with respect to time\n",
    "speed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\n",
    "plt.scatter(time,speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random noise was added, since measuring things manually isn't precise. This means its not that easy to answer the question: what was the roller coaster's speed?\n",
    "\n",
    "Using SGD, we can try to find a function that matches our observations. We can't consider every possible function, so let's use a guess that it will be quadratic ```a*(time**2)+(b*time)+c```.\n",
    "\n",
    "We want to distinguish clearly between the function's input (time) and its parameters. So let's collect the parameters in one argument and thus separate the input, *t*, and the parameters, *params* in the function's signature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(t, params):\n",
    "    a,b,c = params\n",
    "    return a*(t**2) + (b*t) + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now restricted the problem of finding the best imaginable function that fits the data, to finding the best quadratic function.\n",
    "This greatly simplifies the problem, since every quadratic function is fully defined by the three parameters *a, b and c*. Thus, to find the best quadratic function, we only need to find the best values for *a, b and c*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to find first what we mean by \"best\". We define this precisely by choosing a *loss* function, which will return a value based on a prediction and a target, where lower values of the function correspond to \"better\" predictions. It is important for loss functions to return *lower* values when predictions are more accurate, as the SGD procedure we defined earlier will try to *minimise* this loss.\n",
    "\n",
    "For continuous data, it's common to use *mean squared error*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Loss Function\n",
    "def mse(preds, targets): return ((preds-targets)**2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's work through Arthur Samuel's 7 Step Process.\n",
    "\n",
    "### Step 1: Initialise the Parameters\n",
    "\n",
    "First, we initialise the parameters to random values, and tell PyTorch that we want to track their gradients using ```requires_grad_```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising random parameters\n",
    "params = torch.randn(3).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Calculate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the predictions\n",
    "preds = f(time, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to see how close our predictions are to our targets, and take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_preds(preds, ax=None):\n",
    "    if ax is None: ax=plt.subplots()[1]\n",
    "    ax.scatter(time, speed)\n",
    "    ax.scatter(time, to_np(preds), color='red')\n",
    "    ax.set_ylim(-300,100)\n",
    "\n",
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This doesn't look very close. Our random parameters suggest that the rollercoaster will end up going backwards, since we have negative speeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Calculate the Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the loss using the mean squared error function we defined previously\n",
    "loss = mse(preds, speed)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to improve this. To do that, we'll need to know the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Calculate the Gradients\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating an approximation of how the parameters need to change (aka. the gradient)\n",
    "\n",
    "loss.backward()\n",
    "params.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use these gradients to improve our parameters. We'll need to pick a learning rate which we'll use 1e-5 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.grad * 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Step the Weights\n",
    "\n",
    "We need to update the parameters based on the gradients we just calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimiser Step\n",
    "lr = 1e-5\n",
    "params.data -= lr * params.grad.data\n",
    "params.grad = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if the loss has improved and take a look at the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = f(time,params)\n",
    "mse(preds,speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_preds(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has reduced the error!\n",
    "We now need to repeat this step a few times, so we'll create a function to apply one step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_step(params, prn=True):\n",
    "    preds = f(time, params)\n",
    "    loss = mse(preds, speed)\n",
    "    loss.backward()\n",
    "    params.data -= lr * params.grad.data\n",
    "    params.grad = None\n",
    "    if prn: print(loss.item())\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Repeating the Process\n",
    "\n",
    "We now iterate by looping and performing many improvements with the hope that we reach a good result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over 10 epochs\n",
    "for i in range(10): apply_step(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loss is going down, just as we had hopped.\n",
    "\n",
    "But looking only at these loss numbers diguises the fact that each iteration represents an entirely different quadratic function being tried, on the way to finding the best possible quadratic function.\n",
    "\n",
    "We can see this process visually if, instead of printing out the loss function, we plot the function at every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,axs = plt.subplots(1,4,figsize=(12,3))\n",
    "for ax in axs: show_preds(apply_step(params, False), ax)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Stop\n",
    "\n",
    "We just decided to stop after 10 epochs arbitrarily. In practice, we would watch the training and validation losses and our metrics to decide when to stop."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e90582675576e512e92beafc5221de7144a1dea5f49197901594ad708e1d2ecb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
